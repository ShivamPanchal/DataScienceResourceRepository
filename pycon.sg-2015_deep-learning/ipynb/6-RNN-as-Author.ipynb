{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characterwise Single Layer GRU as Author\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import theano\n",
    "from theano import tensor\n",
    "\n",
    "from blocks.bricks import Tanh\n",
    "from blocks.bricks.recurrent import GatedRecurrent\n",
    "from blocks.bricks.sequence_generators import (SequenceGenerator, Readout, SoftmaxEmitter, LookupFeedback)\n",
    "from blocks.graph import ComputationGraph\n",
    "\n",
    "import blocks.algorithms\n",
    "from blocks.algorithms import GradientDescent\n",
    "from blocks.initialization import Orthogonal, IsotropicGaussian, Constant\n",
    "from blocks.model import Model\n",
    "\n",
    "from blocks.monitoring import aggregation\n",
    "from blocks.extensions import FinishAfter, Printing\n",
    "from blocks.extensions.saveload import Checkpoint\n",
    "from blocks.extensions.monitoring import TrainingDataMonitoring\n",
    "\n",
    "from blocks.main_loop import MainLoop\n",
    "import blocks.serialization\n",
    "\n",
    "from blocks.select import Selector\n",
    "\n",
    "import logging\n",
    "import pprint\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "theano.config.floatX='float32'\n",
    "\n",
    "print theano.config.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dictionaries\n",
    "import string\n",
    "\n",
    "all_chars = [ a for a in string.printable]+['<UNK>']\n",
    "code2char = dict(enumerate(all_chars))\n",
    "char2code = {v: k for k, v in code2char.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    data_file = 'Shakespeare.poetry.txt'\n",
    "    dim = 16\n",
    "    hidden_state_dim = 16\n",
    "    feedback_dim = 16\n",
    "else:\n",
    "    data_file = 'Shakespeare.plays.txt'\n",
    "    dim = 64\n",
    "    hidden_state_dim = 64\n",
    "    feedback_dim = 64\n",
    "    \n",
    "seq_len = 256    # The input file is learned in chunks of text this large\n",
    "\n",
    "# Network parameters\n",
    "num_states=len(char2code)  # This is the size of the one-hot input and SoftMax output layers\n",
    "\n",
    "batch_size =  10  # This is for mini-batches : Helps optimize GPU workload\n",
    "num_epochs =   1  # Number of reads-through of corpus to do first training\n",
    "\n",
    "data_path = '../data/'  + data_file\n",
    "save_path = '../models/' + data_file + '.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from fuel.datasets import Dataset\n",
    "from fuel.streams import DataStream\n",
    "from fuel.schemes import ConstantScheme\n",
    "\n",
    "from fuel.datasets import Dataset\n",
    "\n",
    "class CharacterTextFile(Dataset):\n",
    "    provides_sources = (\"data\",)\n",
    "\n",
    "    def __init__(self, fname, chunk_len, dictionary, **kwargs):\n",
    "        self.fname = fname\n",
    "        self.chunk_len = chunk_len\n",
    "        self.dictionary = dictionary \n",
    "        super(CharacterTextFile, self).__init__(**kwargs)\n",
    "\n",
    "    def open(self):\n",
    "        return open(self.fname,'r')\n",
    "\n",
    "    def get_data(self, state, request):\n",
    "        assert isinstance(request, int)\n",
    "        x = numpy.zeros((self.chunk_len, request), dtype='int64')\n",
    "        for i in range(request):\n",
    "            txt=state.read(self.chunk_len)\n",
    "            if len(txt)<self.chunk_len: raise StopIteration\n",
    "            #print(\">%s<\\n\" % (txt,))\n",
    "            x[:, i] = [ self.dictionary[c] for c in txt ]\n",
    "        return (x,)    \n",
    "    \n",
    "    def close(self, state):\n",
    "        state.close()\n",
    "        \n",
    "dataset = CharacterTextFile(data_path, chunk_len=seq_len, dictionary=char2code)\n",
    "data_stream = DataStream(dataset, iteration_scheme=ConstantScheme(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=data_stream.get_data(10)  # i.e. ask for 10 samples of 256(=seq_len) characters\n",
    "a[0].shape  # (256, 10) - essentially, a 10 separate streams of 256 characters \n",
    "#[ code2char[v] for v in [94, 27, 21, 94, 16, 14, 54, 23, 14, 12] ]     # Horizontal stripe in matrix \n",
    "#[ code2char[v] for v in [94, 94,95,36,94,47,50,57,40,53,68,54,94,38] ] # Vertical stripe in matrix\n",
    "''.join([ code2char[v] for v in a[0][:,0] ])  # This a vertical strip - same as markov_chain example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model\n",
    "Actually, it's a single layer of GRU for now...  (rather than a double-stacked LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transition = GatedRecurrent(name=\"transition\", dim=hidden_state_dim, activation=Tanh())\n",
    "generator =  SequenceGenerator(\n",
    "                Readout(readout_dim=num_states, source_names=[\"states\"],\n",
    "                        emitter=SoftmaxEmitter(name=\"emitter\"),\n",
    "                        feedback_brick=LookupFeedback(\n",
    "                            num_states, feedback_dim, name='feedback'),\n",
    "                        name=\"readout\"),\n",
    "                transition,\n",
    "                weights_init=IsotropicGaussian(0.01), biases_init=Constant(0),\n",
    "                name=\"generator\"\n",
    ")\n",
    "\n",
    "generator.push_initialization_config()\n",
    "transition.weights_init = Orthogonal()\n",
    "generator.initialize()\n",
    "\n",
    "print(generator.readout.emitter.readout_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "That's the underlying network defined - now need to create the infrastructure to iteratively improve it :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logger.info(\"Parameters:\\n\" + pprint.pformat(\n",
    "    [(key, value.get_value().shape) for key, value in Selector(generator).get_params().items()],\n",
    "    width=120))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the cost computation graph :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tensor.lmatrix('data')\n",
    "cost = aggregation.mean(generator.cost_matrix(x[:, :]).sum(), x.shape[1])\n",
    "cost.name = \"sequence_log_likelihood\"\n",
    "\n",
    "model=Model(cost)\n",
    "\n",
    "algorithm = GradientDescent(\n",
    "    cost=cost, params=list(Selector(generator).get_params().values()),\n",
    "    step_rule=blocks.algorithms.CompositeRule([blocks.algorithms.StepClipping(10.0), blocks.algorithms.Scale(0.01)]) )  \n",
    "# tried: blocks.algorithms.Scale(0.001), blocks.algorithms.RMSProp(), blocks.algorithms.AdaGrad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model can now be shown as a Compute Graph\n",
    "(But this is time consuming, and the image will be huge...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  from IPython.display import SVG\n",
    "#  SVG(theano.printing.pydotprint(cost, return_image=True, format='svg'))\n",
    "#from IPython.display import Image\n",
    "#Image(theano.printing.pydotprint(cost, return_image=True, format='png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Define the Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_loop = MainLoop(\n",
    "    algorithm=algorithm,\n",
    "    data_stream=data_stream,\n",
    "    model=model,\n",
    "    extensions=[\n",
    "        FinishAfter(after_n_epochs=num_epochs),\n",
    "        TrainingDataMonitoring([cost], prefix=\"this_step\", after_batch=True),\n",
    "        TrainingDataMonitoring([cost], prefix=\"average\",   every_n_batches=100),\n",
    "        Checkpoint(save_path, every_n_batches=1000),\n",
    "        Printing(every_n_batches=500)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run (or continue) the Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "main_loop.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate here to sample the learned relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_length = 1000  # in characters\n",
    "\n",
    "sampler = ComputationGraph(\n",
    "    generator.generate(n_steps=output_length, batch_size=1, iterate=True)\n",
    ")\n",
    "\n",
    "sample = sampler.get_theano_function()\n",
    "states, outputs, costs = [data[:, 0] for data in sample()]\n",
    "\n",
    "numpy.set_printoptions(precision=3, suppress=True)\n",
    "print(\"Generation cost:\\n{}\".format(costs.sum()))\n",
    "\n",
    "print(''.join([ code2char[c] for c in outputs]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To continue the training, go up to the ``main_loop.run()`` cell above, and execute it.\n",
    "\n",
    "When you want to see another sample of the results, halt the execution, and wait for it to complete (with ``TRAINING HAS BEEN FINISHED`` in the output text box).  \n",
    "\n",
    "Then just evaluate the sampling cell (the one just above this one).\n",
    "\n",
    "Repeat according to taste..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}