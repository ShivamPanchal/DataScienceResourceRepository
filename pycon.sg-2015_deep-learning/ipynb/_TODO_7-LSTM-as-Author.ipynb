{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characterwise Double-Stacked LSTM as Author\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import theano\n",
    "from theano import tensor\n",
    "\n",
    "from blocks.bricks import Tanh\n",
    "from blocks.bricks.recurrent import GatedRecurrent\n",
    "from blocks.bricks.sequence_generators import (SequenceGenerator, Readout, SoftmaxEmitter, LookupFeedback)\n",
    "from blocks.graph import ComputationGraph\n",
    "\n",
    "import blocks.algorithms\n",
    "from blocks.algorithms import GradientDescent\n",
    "from blocks.initialization import Orthogonal, IsotropicGaussian, Constant\n",
    "from blocks.model import Model\n",
    "\n",
    "from blocks.monitoring import aggregation\n",
    "from blocks.extensions import FinishAfter, Printing\n",
    "from blocks.extensions.saveload import Checkpoint\n",
    "from blocks.extensions.monitoring import TrainingDataMonitoring\n",
    "\n",
    "from blocks.main_loop import MainLoop\n",
    "import blocks.serialization\n",
    "\n",
    "from blocks.select import Selector\n",
    "\n",
    "import logging\n",
    "import pprint\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "theano.config.floatX='float32'\n",
    "\n",
    "print theano.config.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dictionaries\n",
    "import string\n",
    "\n",
    "all_chars = [ a for a in string.printable]+['<UNK>']\n",
    "code2char = dict(enumerate(all_chars))\n",
    "char2code = {v: k for k, v in code2char.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    data_file = 'Shakespeare.poetry.txt'\n",
    "    dim = 32\n",
    "    hidden_state_dim = 32\n",
    "    feedback_dim = 32\n",
    "else:\n",
    "    data_file = 'Shakespeare.plays.txt'\n",
    "    dim = 64\n",
    "    hidden_state_dim = 64\n",
    "    feedback_dim = 64\n",
    "    \n",
    "seq_len = 256    # The input file is learned in chunks of text this large\n",
    "\n",
    "# Network parameters\n",
    "num_states=len(char2code)  # This is the size of the one-hot input and SoftMax output layers\n",
    "\n",
    "batch_size = 100   # This is for mini-batches : Helps optimize GPU workload\n",
    "num_epochs = 100  # Number of reads-through of corpus to do a training\n",
    "\n",
    "data_path = '../data/'  + data_file\n",
    "save_path = '../models/' + data_file + '.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from fuel.datasets import Dataset\n",
    "from fuel.streams import DataStream\n",
    "from fuel.schemes import ConstantScheme\n",
    "\n",
    "from fuel.datasets import Dataset\n",
    "\n",
    "#from fuel.datasets import TextFile\n",
    "#dataset = TextFile([data_file], bos_token=None, eos_token=None, level=\"character\", dictionary=char2code)\n",
    "#data_stream = DataStream(dataset, iteration_scheme=ConstantScheme(batch_size))\n",
    "\n",
    "class CharacterTextFile(Dataset):\n",
    "    provides_sources = (\"data\",)\n",
    "\n",
    "    def __init__(self, fname, chunk_len, dictionary, **kwargs):\n",
    "        self.fname = fname\n",
    "        self.chunk_len = chunk_len\n",
    "        self.dictionary = dictionary \n",
    "        super(CharacterTextFile, self).__init__(**kwargs)\n",
    "\n",
    "    def open(self):\n",
    "        return open(self.fname,'r')\n",
    "\n",
    "    def get_data(self, state, request):\n",
    "        assert isinstance(request, int)\n",
    "        x = numpy.zeros((self.chunk_len, request), dtype='int64')\n",
    "        for i in range(request):\n",
    "            txt=state.read(self.chunk_len)\n",
    "            if len(txt)<self.chunk_len: raise StopIteration\n",
    "            #print(\">%s<\\n\" % (txt,))\n",
    "            x[:, i] = [ self.dictionary[c] for c in txt ]\n",
    "        return (x,)    \n",
    "    \n",
    "    def close(self, state):\n",
    "        state.close()\n",
    "        \n",
    "dataset = CharacterTextFile(data_path, chunk_len=seq_len, dictionary=char2code)\n",
    "data_stream = DataStream(dataset, iteration_scheme=ConstantScheme(batch_size))\n",
    "a=data_stream.get_data(10)\n",
    "#[ code2char[v] for v in [94, 27, 21, 94, 16, 14, 54, 23, 14, 12] ]      # Horizontally\n",
    "#[ code2char[v] for v in [94, 94,95,36,94,47,50,57,40,53,68,54,94,38] ]  # Vertically\n",
    "''.join([ code2char[v] for v in a[0][:,0] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model\n",
    "Actually, it's a single layer of GRU for now...  (rather than a double-stacked LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transition = GatedRecurrent(name=\"transition\", dim=hidden_state_dim, activation=Tanh())\n",
    "generator =  SequenceGenerator(\n",
    "                Readout(readout_dim=num_states, source_names=[\"states\"],\n",
    "                        emitter=SoftmaxEmitter(name=\"emitter\"),\n",
    "                        feedback_brick=LookupFeedback(\n",
    "                            num_states, feedback_dim, name='feedback'),\n",
    "                        name=\"readout\"),\n",
    "                transition,\n",
    "                weights_init=IsotropicGaussian(0.01), biases_init=Constant(0),\n",
    "                name=\"generator\"\n",
    ")\n",
    "\n",
    "generator.push_initialization_config()\n",
    "transition.weights_init = Orthogonal()\n",
    "generator.initialize()\n",
    "\n",
    "#dir(generator.readout.emitter)\n",
    "#print(generator.readout.emitter.get_unique_path())\n",
    "#print(generator.readout.emitter.name)\n",
    "print(generator.readout.emitter.readout_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "That's the underlying network defined - now need to create the infrastructure to iteratively improve it :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Give an idea of what's going on.\n",
    "logger.info(\"Parameters:\\n\" + pprint.pformat(\n",
    "    [(key, value.get_value().shape) for key, value in Selector(generator).get_params().items()],\n",
    "    width=120))\n",
    "#logger.info(\"Markov chain entropy: {}\".format(MarkovChainDataset.entropy))\n",
    "#logger.info(\"Expected min error: {}\".format( -MarkovChainDataset.entropy * seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build the cost computation graph.\n",
    "x = tensor.lmatrix('data')\n",
    "cost = aggregation.mean(generator.cost_matrix(x[:, :]).sum(), x.shape[1])\n",
    "cost.name = \"sequence_log_likelihood\"\n",
    "\n",
    "model=Model(cost)\n",
    "\n",
    "algorithm = GradientDescent(\n",
    "    cost=cost, params=list(Selector(generator).get_params().values()),\n",
    "    step_rule=blocks.algorithms.CompositeRule([blocks.algorithms.StepClipping(10.0), blocks.algorithms.Scale(0.01)]) )  \n",
    "# tried: blocks.algorithms.Scale(0.001), blocks.algorithms.RMSProp(), blocks.algorithms.AdaGrad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model can now be shown as a Compute Graph\n",
    "(But this is time consuming, and the image will be huge...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  from IPython.display import SVG\n",
    "#  SVG(theano.printing.pydotprint(cost, return_image=True, format='svg'))\n",
    "#from IPython.display import Image\n",
    "#Image(theano.printing.pydotprint(cost, return_image=True, format='png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Define the Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_loop = MainLoop(\n",
    "    algorithm=algorithm,\n",
    "    data_stream=data_stream,\n",
    "    model=model,\n",
    "    extensions=[\n",
    "        FinishAfter(after_n_epochs=num_epochs),\n",
    "        TrainingDataMonitoring([cost], prefix=\"this_step\", after_batch=True),\n",
    "        TrainingDataMonitoring([cost], prefix=\"average\",   every_n_batches=100),\n",
    "        Checkpoint(save_path, every_n_batches=1000),\n",
    "        Printing(every_n_batches=500)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run (or continue) the Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "main_loop.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "## continuing models : (new method is not cPickle) :\n",
    "# https://groups.google.com/forum/#!topic/blocks-users/jns-KKWTtko\n",
    "# http://blocks.readthedocs.org/en/latest/serialization.html?highlight=load\n",
    "## To inspect contents of saved/Checkpoint-ed file :\n",
    "# unzip -t models/Shakespeare.poetry.txt.model \n",
    "\n",
    "#from six.moves import cPickle\n",
    "#main_loop = cPickle.load(open(save_path, \"rb\"))\n",
    "#blocks.serialization.load(save_path)\n",
    "\n",
    "\n",
    "#def author(input):    \n",
    "#    pass\n",
    "\n",
    "#model=Model(cost)\n",
    "\n",
    "# Read back in from disk\n",
    "if False:\n",
    "    model.set_param_values(blocks.serialization.load_parameter_values(save_path))\n",
    "# Includes generator(?)\n",
    "#generator = main_loop.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is to sample the learned relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_length = 1000  # in characters\n",
    "\n",
    "sampler = ComputationGraph(\n",
    "    generator.generate(n_steps=output_length, batch_size=1, iterate=True)\n",
    ")\n",
    "\n",
    "#print(\"Sampler variables : \", sampler.variables)\n",
    "\n",
    "sample = sampler.get_theano_function()\n",
    "\n",
    "states, outputs, costs = [data[:, 0] for data in sample()]\n",
    "\n",
    "numpy.set_printoptions(precision=3, suppress=True)\n",
    "print(\"Generation cost:\\n{}\".format(costs.sum()))\n",
    "\n",
    "#freqs = numpy.bincount(outputs).astype(floatX)\n",
    "#freqs /= freqs.sum()\n",
    "#print(\"Frequencies:\\n {} vs {}\".format(freqs, MarkovChainDataset.equilibrium))\n",
    "\n",
    "#trans_freqs = numpy.zeros((num_states, num_states), dtype=floatX)\n",
    "#for a, b in zip(outputs, outputs[1:]):\n",
    "#    trans_freqs[a, b] += 1\n",
    "#trans_freqs /= trans_freqs.sum(axis=1)[:, None]\n",
    "#print(\"Transition frequencies:\\n{}\\nvs\\n{}\".format(\n",
    "#    trans_freqs, MarkovChainDataset.trans_prob))\n",
    "\n",
    "#print(numpy.shape(states))\n",
    "#print(numpy.shape(outputs))\n",
    "#print(outputs[:])\n",
    "print(''.join([ code2char[c] for c in outputs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from blocks.serialization import continue_training\n",
    "#blocks.serialization.continue_training(save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}